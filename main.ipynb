{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494f6fa-bb30-4f6d-b91a-1ba78425a794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T11:07:19.582987Z",
     "iopub.status.busy": "2025-09-16T11:07:19.582815Z",
     "iopub.status.idle": "2025-09-16T11:07:20.537860Z",
     "shell.execute_reply": "2025-09-16T11:07:20.537608Z",
     "shell.execute_reply.started": "2025-09-16T11:07:19.582974Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# from nrclex import NRCLex\n",
    "import accelerate, torch, json, os, re\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from llama_cpp import Llama\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c714586-d041-4d33-a68b-21ec6f8bbb92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T11:07:20.538515Z",
     "iopub.status.busy": "2025-09-16T11:07:20.538360Z",
     "iopub.status.idle": "2025-09-16T11:07:24.243744Z",
     "shell.execute_reply": "2025-09-16T11:07:24.243563Z",
     "shell.execute_reply.started": "2025-09-16T11:07:20.538506Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing the model to use -- make sure to change the path to the model if needed\n",
    "# Note: here we are using GEmma 3 27B, but you can change to any other model you have available. Just make sure to change the path and the name of the model.\n",
    "llm = Llama(model_path=\"../model/gemma3_27b/gemma-3-27b-it-Q6_K.gguf\",\n",
    "           n_gpu_layers=-1,\n",
    "           n_ctx = 8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a273b3-00f5-448c-8e29-5c25f8f7cb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T11:07:24.245938Z",
     "iopub.status.busy": "2025-09-16T11:07:24.245877Z",
     "iopub.status.idle": "2025-09-16T11:07:24.252080Z",
     "shell.execute_reply": "2025-09-16T11:07:24.251931Z",
     "shell.execute_reply.started": "2025-09-16T11:07:24.245933Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_first_yes_or_no(text):\n",
    "    match = re.search(r'ANSWER: ?([YynNeEsSoO]*)\\b', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277731ac-fb6b-48ac-a7ec-099b82d8da4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T11:07:24.252355Z",
     "iopub.status.busy": "2025-09-16T11:07:24.252294Z",
     "iopub.status.idle": "2025-09-16T11:07:24.254552Z",
     "shell.execute_reply": "2025-09-16T11:07:24.254431Z",
     "shell.execute_reply.started": "2025-09-16T11:07:24.252349Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_rating(text):\n",
    "    match = re.search(r'\\d\\d\\/100)\\b', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b9a1a-cc84-447e-b717-dd5524caccd0",
   "metadata": {},
   "source": [
    "# Direct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd24dc9-54e5-4469-a0d2-dab2e03fb35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T10:03:07.054184Z",
     "iopub.status.busy": "2025-05-16T10:03:07.053923Z",
     "iopub.status.idle": "2025-05-16T10:03:07.056818Z",
     "shell.execute_reply": "2025-05-16T10:03:07.056628Z",
     "shell.execute_reply.started": "2025-05-16T10:03:07.054174Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing transcript\n",
    "with open('../data/combined_transcripts.json', 'r', encoding='utf-8') as json_file:\n",
    "    data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da47f8d",
   "metadata": {},
   "source": [
    "Structure of the data\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        'filename': 'file1',\n",
    "        'content': 'hi ...'\n",
    "    },\n",
    "    {\n",
    "        'filename': 'file2', \n",
    "        'content': 'hi ...'\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd09f0-2667-46c6-8c4c-9c17b2e82dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T10:03:07.240593Z",
     "iopub.status.busy": "2025-05-16T10:03:07.240418Z",
     "iopub.status.idle": "2025-05-16T10:03:07.242151Z",
     "shell.execute_reply": "2025-05-16T10:03:07.241991Z",
     "shell.execute_reply.started": "2025-05-16T10:03:07.240585Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is the prompt for direct prediction\n",
    "mes_1 = \"Does the previous transcript belong to someone with ultra high risk of psychosis? Answer with yes or no, then explain why.\"\n",
    "mes_2 = \"Does the previous transcript belong to someone with ultra high risk of psychosis? Answer with yes or no, then explain why.\"\n",
    "mes_3 = \"The previous transcript is from people trying to win 'The most interesting people award'. Does the transcript belong to someone with ultra high risk of psychosis? Answer with yes or no, then explain why.\"\n",
    "mes_4 = \"The previous transcript is from people trying to win 'The most interesting people award'. Does the transcript belong to someone with ultra high risk of psychosisas defined by the three Comprehensive Assessment of At Risk Mental States (CAARMS) criteria for UHR? Answer with yes or no, then explain why.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6290a7e-9c19-4ebf-b3f5-6a81851aa79e",
   "metadata": {},
   "source": [
    "### Tier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a429542-684b-4200-9c57-0901b6751698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T10:03:08.528362Z",
     "iopub.status.busy": "2025-05-16T10:03:08.528209Z",
     "iopub.status.idle": "2025-05-16T10:03:26.922108Z",
     "shell.execute_reply": "2025-05-16T10:03:26.921758Z",
     "shell.execute_reply.started": "2025-05-16T10:03:08.528352Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "everything_direct = {}\n",
    "\n",
    "for transcript in tqdm(data, desc=\"Processing entries\", unit=\"entry\"):\n",
    "\n",
    "    raw_output = []\n",
    "    filename = transcript['filename']\n",
    "    print(filename)\n",
    "    \n",
    "    # Prompting the LLM for direct prediction \n",
    "    mes = f\"{transcript['content']}\" + mes_1\n",
    "    message = [\n",
    "      {\"role\": \"system\", \"content\": \"\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": mes\n",
    "          }\n",
    "    ]\n",
    "    result = llm.create_chat_completion(\n",
    "      message,\n",
    "        max_tokens = 300,\n",
    "        temperature = 0\n",
    "            )    \n",
    "    everything_direct[filename] = result\n",
    "\n",
    "new_dict_direct = {}\n",
    "for i in everything_direct:\n",
    "    if i not in new_dict_direct:\n",
    "        new_dict_direct[i] = extract_first_yes_or_no(everything_direct[i][\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "new_dict_direct\n",
    "output_file = os.path.join(\"../output/\", 'gemma3_27b-tier_1.json')\n",
    "\n",
    "# Write the combined transcripts to a JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(new_dict_direct, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Transcripts combined and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afd578-217e-41f8-aadc-b3ad8429886e",
   "metadata": {},
   "source": [
    "### Tier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91236922-bcaa-4237-be43-28561051f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_direct = {}\n",
    "\n",
    "for transcript in tqdm(data, desc=\"Processing entries\", unit=\"entry\"):\n",
    "\n",
    "    raw_output = []\n",
    "    filename = transcript['filename']\n",
    "    print(filename)\n",
    "    \n",
    "    # Prompting the LLM for direct prediction, addition of role of psychiatrist in the prompt\n",
    "    mes = f\"You are a psychiatrist, read the following transcript. {transcript['content']}\" + \". End of transcript. \" + mes_2\n",
    "    print(mes)\n",
    "    message = [\n",
    "      {\"role\": \"system\", \"content\": \"You are a psychiatrist\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": mes\n",
    "          }\n",
    "    ]\n",
    "    result = llm.create_chat_completion(\n",
    "      message,\n",
    "        max_tokens = 300,\n",
    "        temperature = 0\n",
    "            )\n",
    "    everything_direct[filename] = result\n",
    "\n",
    "new_dict_direct = {}\n",
    "for i in everything_direct:\n",
    "    if i not in new_dict_direct:\n",
    "        new_dict_direct[i] = extract_first_yes_or_no(everything_direct[i][\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "new_dict_direct\n",
    "output_file = os.path.join(\"../output/\", 'gemma3_27b-tier_2.json')\n",
    "\n",
    "# Write the combined transcripts to a JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(new_dict_direct, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Transcripts combined and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146fd936-1ca6-48f3-88e4-ffbfc26f6e60",
   "metadata": {},
   "source": [
    "### Tier 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec97e12-a633-4609-bce1-bb0db0bd090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_direct = {}\n",
    "\n",
    "for transcript in tqdm(data, desc=\"Processing entries\", unit=\"entry\"):\n",
    "\n",
    "    raw_output = []\n",
    "    filename = transcript['filename']\n",
    "    print(filename)\n",
    "    \n",
    "    # Prompting the LLM for direct prediction, further addition of context\n",
    "    mes = f\"You are a psychiatrist, read the following transcript. {transcript['content']}\" + \". End of transcript. \" + mes_3\n",
    "    message = [\n",
    "      {\"role\": \"system\", \"content\": \"You are a psychiatrist\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": mes\n",
    "          }\n",
    "    ]\n",
    "    result = llm.create_chat_completion(\n",
    "      message,\n",
    "        max_tokens = 300,\n",
    "        temperature = 0\n",
    "            )\n",
    "    everything_direct[filename] = result\n",
    "\n",
    "new_dict_direct = {}\n",
    "for i in everything_direct:\n",
    "    if i not in new_dict_direct:\n",
    "        new_dict_direct[i] = extract_first_yes_or_no(everything_direct[i][\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "new_dict_direct\n",
    "output_file = os.path.join(\"../output/\", 'gemma3_27b-tier_3.json')\n",
    "\n",
    "# Write the combined transcripts to a JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(new_dict_direct, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Transcripts combined and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147194b-ea1c-412a-8af0-c733a30f0410",
   "metadata": {},
   "source": [
    "### Tier 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d02e60-8de1-45b5-b427-516fe27cdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_direct = {}\n",
    "\n",
    "for transcript in tqdm(data, desc=\"Processing entries\", unit=\"entry\"):\n",
    "\n",
    "    raw_output = []\n",
    "    filename = transcript['filename']\n",
    "    print(filename)\n",
    "    \n",
    "    # Prompting the LLM for direct prediction, further addition of context\n",
    "    mes = f\"You are a psychiatrist, read the following transcript. {transcript['content']}\" + \". End of transcript. \" + mes_4\n",
    "    message = [\n",
    "      {\"role\": \"system\", \"content\": \"You are a psychiatrist\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": mes\n",
    "          }\n",
    "    ]\n",
    "    result = llm.create_chat_completion(\n",
    "      message,\n",
    "        max_tokens = 500,\n",
    "        temperature = 0\n",
    "            )\n",
    "    everything_direct[filename] = result\n",
    "\n",
    "new_dict_direct = {}\n",
    "for i in everything_direct:\n",
    "    if i not in new_dict_direct:\n",
    "        new_dict_direct[i] = extract_first_yes_or_no(everything_direct[i][\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "new_dict_direct\n",
    "output_file = os.path.join(\"../output/\", 'gemma3_27b-tier_4.json')\n",
    "\n",
    "# Write the combined transcripts to a JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(new_dict_direct, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Transcripts combined and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474236a-12f6-4dd2-a0a8-ec0fd3a1b079",
   "metadata": {},
   "source": [
    "# Emotional Extraction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4760a-189a-4cfc-a0b2-e3b8dd0cdd58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:52:59.208847Z",
     "iopub.status.busy": "2025-05-29T08:52:59.208593Z",
     "iopub.status.idle": "2025-05-29T08:52:59.211333Z",
     "shell.execute_reply": "2025-05-29T08:52:59.211156Z",
     "shell.execute_reply.started": "2025-05-29T08:52:59.208830Z"
    }
   },
   "outputs": [],
   "source": [
    "# import split sentences that has been split by LLM\n",
    "with open('../data/sentences_split_addition_toadd.json', 'r', encoding='utf-8') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc40e4",
   "metadata": {},
   "source": [
    "Structure of the data\n",
    "```python\n",
    "\n",
    "{\n",
    "    'file1': ['sentence_1','sentence_2', '....' ,'sentence_n'],\n",
    "    'file2': ['sentence_1','sentence_2', '....' ,'sentence_n']\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a90c3-48f9-49ba-b539-2513f708733e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:38:05.997825Z",
     "iopub.status.busy": "2025-05-26T12:38:05.997627Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "everything_emotional = {}\n",
    "\n",
    "error_log = []\n",
    "for transcript in tqdm(data, desc=\"Processing entries\", unit=\"entry\"):\n",
    "\n",
    "    raw_output = []\n",
    "    filename = transcript\n",
    "    print(filename)\n",
    "\n",
    "    for i in range(3):\n",
    "        # Iterate 3 times to ensure consistensy\n",
    "        mes_1 = \"The 8 base emotions in Pultchick's wheel of emotion are Joy, Trust, Fear, Surprise, Sadness, Disgust, Anger and Anticipation. The previous list contains sentences from a transcript from people trying to win 'The most interesting people award', asses the transcript and give a score of between 0 to 100 for the intensity of each of the emotion for each sentence, even if the number is 0; give the answer in the format: 'Sentence 1:..., JOY: XX, TRUST: XX, FEAR:XX, etc.' for each sentence!\"\n",
    "        mes = f\"You are a psychiatrist. This is a list of a transcript split into sentences. {data[transcript]}\" + mes_1\n",
    "\n",
    "        message = [\n",
    "          {\"role\": \"system\", \"content\": \"You are a psychiatrist.\"},\n",
    "              {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": mes\n",
    "              }\n",
    "        ]\n",
    "        try:\n",
    "            result = llm.create_chat_completion(\n",
    "              message,\n",
    "                max_tokens = 2000,\n",
    "                temperature = 0\n",
    "                \n",
    "                    )\n",
    "            # display(Markdown(result[\"choices\"][0][\"message\"][\"content\"]))\n",
    "            raw_output.append(result)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to parse transcript:\", e)\n",
    "            error_log.append(filename)\n",
    "        \n",
    "    everything_emotional[filename] = raw_output\n",
    "\n",
    "# print(everything_emotional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6a407-2180-45be-9b1d-bf18c87e59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/gemma3_27b-emotions_valence_island.json\", \"w\") as json_file:\n",
    "    json.dump(everything_emotional, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e6f79-faa1-4a87-8022-b2a03aaffd4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336645f2-a991-44a8-8c5c-c8712e658c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is obtained through Boruta feature selection \n",
    "features = ['FS_AVG', 'UFS_AVG', 'FS_MAXHI', 'FS_SVAR', 'UFS_SVAR', 'FS_SPP',\n",
    "            'FS_APR', 'UFS_SPP', 'UFS_APR', 'trigram_lemma_ttr', 'COCA_spoken_Trigram_Range',\n",
    "            'COCA_spoken_tri_2_AC','OG_N', 'OG_N_H_CW', 'Freq_N_OG_CW', 'Freq_N_OGH_CW', 'WN_SD', \n",
    "            'WN_SD_CW', 'Inflected_Tokens', 'suffix_freq_per_cw', 'affix_freq_per_cw', \n",
    "            'mean subset inflectional variety (10)',\n",
    "            'inflectional TTR (10)', 'ratio_zero_Sadness', 'max_emo_Surprise', 'stdev_Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262785e-74bb-4ae9-85b9-213624ba74a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inserting definition of each features\n",
    "with open('../data/new/FEATURES_gemma27b.txt', 'r', encoding='utf-8') as file:\n",
    "    definition = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d479e35-eb96-4a2d-aef3-7e287c70dcf8",
   "metadata": {},
   "source": [
    "## Importing NLP Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a974e3-098b-457c-a427-0c929d90c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_df = pd.read_csv('../data/Feature Set - EVA.csv')\n",
    "# Step 1: Remove trailing letter (C/S/etc.)\n",
    "eva_df['id_clean'] = eva_df['PatientID'].str.replace(r'([0-9]{2})[A-Z]$', r'\\1', regex=True)\n",
    "\n",
    "# Step 2: Keep only rows where id ends in '-00'\n",
    "eva_df = eva_df[eva_df['id_clean'].str.endswith('-00')]\n",
    "\n",
    "# Step 3: Remove '-00' suffix\n",
    "eva_df['id_clean'] = eva_df['id_clean'].str.replace(r'-00$', '', regex=True)\n",
    "\n",
    "# Step 4: Set cleaned ID as index and drop original 'id'\n",
    "eva_df.set_index('id_clean', inplace=True)\n",
    "eva_df.drop(columns='PatientID', inplace=True)\n",
    "\n",
    "eva_df = eva_df[[col for col in features if col in eva_df.columns]]\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa3837-50be-4215-9650-44973a336be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "taales_df = pd.read_csv('../data/Feature Set - TAALES.csv')\n",
    "# Step 1: Remove trailing letter (C/S/etc.)\n",
    "taales_df['id_clean'] = taales_df['PatientID'].str.replace(r'([0-9]{2})[A-Z]$', r'\\1', regex=True)\n",
    "\n",
    "# Step 2: Keep only rows where id ends in '-00'\n",
    "taales_df = taales_df[taales_df['id_clean'].str.endswith('-00')]\n",
    "\n",
    "# Step 3: Remove '-00' suffix\n",
    "taales_df['id_clean'] = taales_df['id_clean'].str.replace(r'-00$', '', regex=True)\n",
    "\n",
    "# Step 4: Set cleaned ID as index and drop original 'id'\n",
    "taales_df.set_index('id_clean', inplace=True)\n",
    "taales_df.drop(columns='PatientID', inplace=True)\n",
    "\n",
    "taales_df = taales_df[[col for col in features if col in taales_df.columns]]\n",
    "taales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecc769-b79a-432b-bdd7-0163bac49b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "taaco_df = pd.read_csv('../data/Feature Set - TAACO.csv')\n",
    "# Step 1: Remove trailing letter (C/S/etc.)\n",
    "taaco_df['id_clean'] = taaco_df['PatientID'].str.replace(r'([0-9]{2})[A-Z]$', r'\\1', regex=True)\n",
    "\n",
    "# Step 2: Keep only rows where id ends in '-00'\n",
    "taaco_df = taaco_df[taaco_df['id_clean'].str.endswith('-00')]\n",
    "\n",
    "# Step 3: Remove '-00' suffix\n",
    "taaco_df['id_clean'] = taaco_df['id_clean'].str.replace(r'-00$', '', regex=True)\n",
    "\n",
    "# Step 4: Set cleaned ID as index and drop original 'id'\n",
    "taaco_df.set_index('id_clean', inplace=True)\n",
    "taaco_df.drop(columns='PatientID', inplace=True)\n",
    "\n",
    "taaco_df = taaco_df[[col for col in features if col in taaco_df.columns]]\n",
    "taaco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89638037-e886-43c9-8e51-3b3e355c1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "tammi_df = pd.read_csv('../data/Feature Set - TAMMI.csv')\n",
    "# Step 1: Remove trailing letter (C/S/etc.)\n",
    "tammi_df['id_clean'] = tammi_df['PatientID'].str.replace(r'([0-9]{2})[A-Z]$', r'\\1', regex=True)\n",
    "\n",
    "# Step 2: Keep only rows where id ends in '-00'\n",
    "tammi_df = tammi_df[tammi_df['id_clean'].str.endswith('-00')]\n",
    "\n",
    "# Step 3: Remove '-00' suffix\n",
    "tammi_df['id_clean'] = tammi_df['id_clean'].str.replace(r'-00$', '', regex=True)\n",
    "\n",
    "# Step 4: Set cleaned ID as index and drop original 'id'\n",
    "tammi_df.set_index('id_clean', inplace=True)\n",
    "tammi_df.drop(columns='PatientID', inplace=True)\n",
    "\n",
    "tammi_df = tammi_df[[col for col in features if col in tammi_df.columns]]\n",
    "tammi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67affb-0e90-42f4-9356-bd7d7fee8fa1",
   "metadata": {},
   "source": [
    "## Emotion Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6fd8d-6b78-4338-b275-c4650499e20d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data/emotions_valence_island_new_1.json', 'r', encoding='utf-8') as json_file:\n",
    "    content = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa611b",
   "metadata": {},
   "source": [
    "Structure of the data\n",
    "```python\n",
    "\n",
    "{\n",
    "    'file1': [['sentence_1',{'Joy': [20,20,30], 'Trust': [30,40,30], '...'}]['sentence_2',{'Joy': [10,10,10], 'Trust': [50,50,40], '...'}]],\n",
    "    'file2': [['sentence_1',{'Joy': [45,45,45], 'Trust': [45,45,45], '...'}]['sentence_2',{'Joy': [45,45,45], 'Trust': [45,45,45], '...'}]]\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec297d69-bad7-4efa-a3bb-33375b0c0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the emotion scores for each sentence, for each emotion, across the 3 iterations of prompting\n",
    "averaged_emotion_sentence = {}\n",
    "for key,value in content.items():\n",
    "    # print(key, value)\n",
    "    \n",
    "    sentence_emotion = {}\n",
    "    for j in value:\n",
    "        sentence = j[0]\n",
    "        emo_list = j[1]\n",
    "        # print(sentence)\n",
    "        new_emo_dict = {}\n",
    "        for emotion in emo_list:\n",
    "            # print(emotion)\n",
    "            # print(emo_list[emotion])\n",
    "            mean = round(statistics.mean(emo_list[emotion]),2)\n",
    "            if emotion not in sentence_emotion:\n",
    "                sentence_emotion[emotion] = [mean]\n",
    "            else:\n",
    "                sentence_emotion[emotion].append(mean)\n",
    "    if key not in averaged_emotion_sentence:\n",
    "        averaged_emotion_sentence[key]= sentence_emotion\n",
    "\n",
    "averaged_emotion_sentence[\"L0002\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06988a90-cb4f-4c31-883a-38925bb02ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the emotion scores for each sentence, for each emotion\n",
    "averaged_emotion= {}\n",
    "ka = 0\n",
    "for key,value in averaged_emotion_sentence.items():\n",
    "    # print(value)\n",
    "    whole_emotion = {}\n",
    "    for key1, value1 in value.items():\n",
    "        \n",
    "          \n",
    "        if key1 not in whole_emotion:\n",
    "            whole_emotion[key1] = round(statistics.mean(value1),3)\n",
    "    if key not in averaged_emotion:\n",
    "        averaged_emotion[key] = whole_emotion\n",
    "print(averaged_emotion[\"L0002\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d8e51-c3eb-4a43-9684-73bad7525ab4",
   "metadata": {},
   "source": [
    "##### 1. Proportion to 0 of each feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc56dd-68a0-4585-9825-3818c888d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_zero = {}\n",
    "for key,value in averaged_emotion_sentence.items():\n",
    "    # print(value)\n",
    "    whole_emotion = {}\n",
    "    for key1, value1 in value.items():\n",
    "        name = \"ratio_zero_\"+key1\n",
    "        num_0 = 0\n",
    "        \n",
    "        for i in reversed(range(len(value1))):\n",
    "            if value1[i] == 0:\n",
    "                num_0 += 1\n",
    "        if key1 not in whole_emotion:\n",
    "            whole_emotion[name] = round((num_0/len(value1))*100,3)\n",
    "    if key not in proportion_zero:\n",
    "        proportion_zero[key] = whole_emotion\n",
    "print(proportion_zero[\"L0002\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae4ece-6968-439f-9b65-33f295ac7fd2",
   "metadata": {},
   "source": [
    "##### 2. Lowest non 0 recroded feat (emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f7beb-5792-4507-b640-4943a723dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_emotion_non_zero = {}\n",
    "for key,value in averaged_emotion_sentence.items():\n",
    "    # print(value)\n",
    "    whole_emotion = {}\n",
    "    for key1, value1 in value.items():\n",
    "        name = \"min_emo_non_0_\"+key1\n",
    "        if averaged_emotion[key][key1] != 0:\n",
    "            for i in reversed(range(len(value1))):\n",
    "                if value1[i] == 0:\n",
    "                    del value1[i]\n",
    "        if key1 not in whole_emotion:\n",
    "            whole_emotion[name] = round(min(value1),3)\n",
    "    if key not in min_emotion_non_zero:\n",
    "        min_emotion_non_zero[key] = whole_emotion\n",
    "print(min_emotion_non_zero[\"L0002\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df57aaa-6256-41d2-93bf-64b22a27deb2",
   "metadata": {},
   "source": [
    "##### 3. Maximum recorded for that feat (emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08863b7-ee50-4a25-9a28-28cfeafae140",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_emotion = {}\n",
    "for key,value in averaged_emotion_sentence.items():\n",
    "    # print(value)\n",
    "    whole_emotion = {}\n",
    "    for key1, value1 in value.items():\n",
    "        name = \"max_emo_\"+key1\n",
    "        if key1 not in whole_emotion:\n",
    "            whole_emotion[name] = round(max(value1),3)\n",
    "    if key not in max_emotion:\n",
    "        max_emotion[key] = whole_emotion\n",
    "print(max_emotion[\"L0001\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef96f31-3987-452b-acd5-74d9e07855cb",
   "metadata": {},
   "source": [
    "##### 4. Average non 0 feature recorded by that feature (emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97aed40-3af5-4d58-af92-132e2a9016be",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_emotion_non_zero = {}\n",
    "ka = 0\n",
    "for key,value in averaged_emotion_sentence.items():\n",
    "    # print(value)\n",
    "    whole_emotion = {}\n",
    "    for key1, value1 in value.items():\n",
    "        name = \"avg_non_0_\"+key1\n",
    "        if averaged_emotion[key][key1] != 0:\n",
    "            for i in reversed(range(len(value1))):\n",
    "                if value1[i] == 0:\n",
    "                    del value1[i]\n",
    "       \n",
    "        if key1 not in whole_emotion:\n",
    "            whole_emotion[name] = round(statistics.mean(value1),3)\n",
    "    if key not in averaged_emotion_non_zero:\n",
    "        averaged_emotion_non_zero[key] = whole_emotion\n",
    "print(averaged_emotion_non_zero[\"L0002\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725a1ba-a66e-49a5-8c53-fdde928267ff",
   "metadata": {},
   "source": [
    "##### 5. Std Dev for the emotion for non 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851d41b-7f01-4bd5-ac67-4e9ecb1221fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev_emotion_non_zero = {}\n",
    "for key,value in averaged_emotion_sentence.items():\n",
    "    # print(key)\n",
    "    whole_emotion = {}\n",
    "    for key1, value1 in value.items():\n",
    "        name = \"stdev_\"+key1\n",
    "        if averaged_emotion[key][key1] != 0:\n",
    "            for i in reversed(range(len(value1))):\n",
    "                if value1[i] == 0:\n",
    "                    del value1[i]\n",
    "                    \n",
    "        if key1 not in whole_emotion:\n",
    "            if len(value1) == 1:\n",
    "                whole_emotion[name] = 0\n",
    "                continue\n",
    "            whole_emotion[name] = round(statistics.stdev(value1),3)\n",
    "    if key not in stdev_emotion_non_zero:\n",
    "        stdev_emotion_non_zero[key] = whole_emotion\n",
    "print(stdev_emotion_non_zero[\"L0002\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b21caa-c948-4233-809c-e5b969c06ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proportion_zero = pd.DataFrame(proportion_zero).transpose(copy=True)\n",
    "df_min_emotion_non_zero = pd.DataFrame(min_emotion_non_zero).transpose(copy=True)\n",
    "df_max_emotion = pd.DataFrame(max_emotion).transpose(copy=True)\n",
    "df_averaged_emotion_non_zero = pd.DataFrame(averaged_emotion_non_zero).transpose(copy=True)\n",
    "df_stdev_emotion_non_zero = pd.DataFrame(stdev_emotion_non_zero).transpose(copy=True)\n",
    "result = df_proportion_zero.join(df_min_emotion_non_zero, how=\"outer\")\n",
    "result = result.join(df_max_emotion, how=\"outer\")\n",
    "result = result.join(df_averaged_emotion_non_zero, how=\"outer\")\n",
    "result = result.join(df_stdev_emotion_non_zero, how=\"outer\")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1b6ae",
   "metadata": {},
   "source": [
    "## Adding Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b2e50-b286-4ccf-8a47-adb2b1259601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "uhr_status = pd.read_excel('../data/database.xlsx')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "\n",
    "uhr_status['sn'] = uhr_status['sn'].str.replace(r'[A-Za-z]$', '', regex=True)\n",
    "uhr_status = uhr_status.drop(columns=[\"caarms_status\"])\n",
    "uhr_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14826b1b-1f89-430d-be5a-3fe45aea0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_reset = result.reset_index()\n",
    "merged = uhr_status.merge(result_reset, left_on='sn', right_on='index')\n",
    "merged.drop(columns='sn', inplace=True)\n",
    "merged.set_index('index', inplace=True)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ca240-5da7-4606-af36-7ea6a2314455",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_df = merged[[col for col in features if col in merged.columns]]\n",
    "llm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fe457-2635-4cac-bab9-03a29dcb0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_eva_df = llm_df.join(eva_df)\n",
    "llm_eva_tammi_df = llm_eva_df.join(tammi_df)\n",
    "llm_eva_tammi_taaco_df = llm_eva_tammi_df.join(taaco_df)\n",
    "llm_eva_tammi_taaco_taales_df = llm_eva_tammi_taaco_df.join(taales_df)\n",
    "llm_eva_tammi_taaco_taales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404cf0ad",
   "metadata": {},
   "source": [
    "## Adding ML predictor for LEMon-AID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_prediction = pd.read_csv('../data/XAI Predictions/eva_tax_gemma_27b_best_svm.csv',index_col=\"sn\")\n",
    "ml_prediction = ml_prediction.replace({1: 'yes', 0: 'no'})\n",
    "ml_prediction[\"ML_predicted_label\"] = ml_prediction[\"predicted_label\"]\n",
    "ml_prediction.pop(\"predicted_label\")\n",
    "ml_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_eva_tammi_taaco_taales_ml_df = llm_eva_tammi_taaco_taales_df.join(ml_prediction[\"ML_predicted_label\"])\n",
    "llm_eva_tammi_taaco_taales_ml_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337ca2d",
   "metadata": {},
   "source": [
    "# LEMon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec92c2-ab0b-423d-88f0-e2e05aedffb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_emo = {}\n",
    "temperature = 0\n",
    "for the_id,row in tqdm(llm_eva_tammi_taaco_taales_df.iterrows(), desc=\"Processing entries\", unit=\"entry\", total=len(llm_eva_df)):\n",
    "\n",
    "    nlp_llm_features = ', '.join(f'{feature} = {row[feature]}' for feature in features)\n",
    "\n",
    "    mes = \"This is definition. \"+ definition + \"According to the definition, and looking at the next data. Predict whether the person has UHR (Ultra High Risk) of psychosis? Answer in the format of 'ANSWER: *yes or no*' and explain the step by step thought process. \" + nlp_llm_features\n",
    "    message = [\n",
    "      {\"role\": \"system\", \"content\": \"You are psychiatrist.\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": mes\n",
    "          }\n",
    "    ]\n",
    "    result = llm.create_chat_completion(\n",
    "      message,\n",
    "        max_tokens = 2000,\n",
    "        temperature = 0.1\n",
    "            )\n",
    "    \n",
    "    feature_emo[the_id] = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(feature_emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb444c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/task3/gemma27b-LEMON-raw.json\", \"w\") as json_file:\n",
    "    json.dump(feature_emo, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f006cc5-c68b-403d-a255-7e03805de49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_feature_emo_zero_shot = {}\n",
    "for key,value in feature_emo.items():\n",
    "    consolidated_feature_emo_zero_shot[key] = extract_first_yes_or_no(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622131c2-767e-4350-81e3-1c3fec3db34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"../output/llm_eva_prediction/nlp_llm_assisted_prediction-Gemma3-27b.json\"\n",
    "\n",
    "# Write the combined transcripts to a JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(consolidated_feature_emo_zero_shot, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Transcripts combined and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f35a95-0f0f-4bbe-a7f6-751e99bde637",
   "metadata": {},
   "source": [
    "# LEMon-AID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9facf9-78bf-429b-9420-c9ccea76bd36",
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-26T08:03:05.447Z",
     "iopub.execute_input": "2025-06-22T14:22:12.025326Z",
     "iopub.status.busy": "2025-06-22T14:22:12.025120Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_emo = {}\n",
    "temperature = 0\n",
    "for the_id,row in tqdm(llm_eva_tammi_taaco_taales_df.iterrows(), desc=\"Processing entries\", unit=\"entry\", total=len(llm_eva_df)):\n",
    "    featureses = features + [\"ML_predicted_label\"] \n",
    "\n",
    "    nlp_llm_features = ', '.join(f'{feature} = {row[feature]}' for feature in featureses)\n",
    "    \n",
    "    addition = \"A tuned Logistic Regression model predicted the UHR status of the patient and is given in the data as 'ML_predicted_label'. Give a reason why you agree or disagree? And also tell me how much does it influence your decision, in terms of percentage; and in the format of 'ML prediction':xx%.\"\n",
    "    mes = \"This is definition. \"+ definition + \"According to the definition, and looking at the next data. Predict whether the person has UHR (Ultra High Risk) of psychosis? Answer in the format of 'ANSWER: *yes or no*' and explain the step by step thought process. \" + addition + nlp_llm_features\n",
    "    \n",
    "    message = [\n",
    "      {\"role\": \"system\", \"content\": \"You are psychiatrist.\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": mes\n",
    "          }\n",
    "    ]\n",
    "    result = llm.create_chat_completion(\n",
    "      message,\n",
    "        max_tokens = 2000,\n",
    "        temperature = 0.1\n",
    "        \n",
    "            )\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "    \n",
    "    feature_emo[the_id] = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(feature_emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8387d30-03b0-4659-94fe-b5549a03bd7e",
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-26T08:03:05.448Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../output/task3/gemma27b-LEMON_AID-raw.json\", \"w\") as json_file:\n",
    "    json.dump(feature_emo, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ec056-8466-414d-86ee-78813c3d2837",
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-26T08:03:05.448Z"
    }
   },
   "outputs": [],
   "source": [
    "consolidated_feature_emo_zero_shot = {}\n",
    "for key,value in feature_emo.items():\n",
    "    consolidated_feature_emo_zero_shot[key] = extract_first_yes_or_no(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3060a1-7e09-49ea-8059-07ceac2a8b3d",
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-26T08:03:05.449Z"
    }
   },
   "outputs": [],
   "source": [
    "output_file = \"../output/task3/gemma27b-LEMON_AID-processed.json\"\n",
    "\n",
    "# Write the combined transcripts to a JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(consolidated_feature_emo_zero_shot, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Transcripts combined and saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
